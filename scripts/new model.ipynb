{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592c3f9d",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2361bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "import timm\n",
    "from timm.data import resolve_model_data_config, create_transform\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "287aa55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/Data/images_1000\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\"/Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/Data/images_1000\")\n",
    "OUT_DIR  = Path(\"/Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "assert DATA_DIR.exists(), \"DATA_DIR not found!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a654c1",
   "metadata": {},
   "source": [
    "Device & speed knobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4687356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device wählen (MPS = Apple GPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Speed/Training Knobs\n",
    "BATCH = 32 if device in (\"mps\", \"cuda\") else 8\n",
    "NUMW  = 0        # macOS → safer\n",
    "PIN   = (device == \"cuda\")\n",
    "\n",
    "EPOCHS_HEAD = 40   # Kopf trainieren\n",
    "EPOCHS_FT   = 6    # Fine-Tuning\n",
    "PATIENCE    = 5    # Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c295a",
   "metadata": {},
   "source": [
    "## Dataset (1,000 imgs / 10 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f07506bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Abstract_Expressionism', 'Cubism', 'Expressionism', 'Impressionism', 'Neoclassicism', 'Post-Impressionism', 'Realism', 'Romanticism', 'Surrealism', 'Symbolism'] (10)\n",
      "Per-class counts: Counter({0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100})\n",
      "Num train/val/test: 700 150 150\n"
     ]
    }
   ],
   "source": [
    "# Dataset laden, nur um Klassen zu sehen\n",
    "tmp_ds = datasets.ImageFolder(DATA_DIR, transform=None)\n",
    "classes = tmp_ds.classes\n",
    "num_classes = len(classes)\n",
    "print(\"Classes:\", classes, f\"({num_classes})\")\n",
    "\n",
    "# Anzahl Bilder pro Klasse checken\n",
    "counts = Counter([lbl for _, lbl in tmp_ds.samples])\n",
    "print(\"Per-class counts:\", counts)\n",
    "\n",
    "# Stratified Split Funktion\n",
    "def stratified_split(samples, val_ratio=0.15, test_ratio=0.15, seed=SEED):\n",
    "    y = np.array([c for _, c in samples])\n",
    "    idxs = np.arange(len(y))\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for c in np.unique(y):\n",
    "        c_idx = idxs[y == c]\n",
    "        rng.shuffle(c_idx)\n",
    "        n = len(c_idx)\n",
    "        n_test = int(round(n * test_ratio))\n",
    "        n_val  = int(round(n * val_ratio))\n",
    "        n_train = n - n_val - n_test\n",
    "        train_idx += list(c_idx[:n_train])\n",
    "        val_idx   += list(c_idx[n_train:n_train+n_val])\n",
    "        test_idx  += list(c_idx[n_train+n_val:])\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "train_idx, val_idx, test_idx = stratified_split(tmp_ds.samples, 0.15, 0.15)\n",
    "print(\"Num train/val/test:\", len(train_idx), len(val_idx), len(test_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df0999",
   "metadata": {},
   "source": [
    "# Model + Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f2be5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train/val/test: 700 150 150\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"resnet18.a1_in1k\"\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "cfg = resolve_model_data_config(model)\n",
    "tfm_train = create_transform(**cfg, is_training=True)\n",
    "tfm_val   = create_transform(**cfg, is_training=False)\n",
    "\n",
    "# Datasets mit Transforms\n",
    "full_train = datasets.ImageFolder(DATA_DIR, transform=tfm_train)\n",
    "full_val   = datasets.ImageFolder(DATA_DIR, transform=tfm_val)\n",
    "full_test  = datasets.ImageFolder(DATA_DIR, transform=tfm_val)\n",
    "\n",
    "train_ds = Subset(full_train, train_idx)\n",
    "val_ds   = Subset(full_val,   val_idx)\n",
    "test_ds  = Subset(full_test,  test_idx)\n",
    "\n",
    "print(\"Num train/val/test:\", len(train_ds), len(val_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a743b18",
   "metadata": {},
   "source": [
    "# Loaders + imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights (handle imbalance even if slight)\n",
    "y_train = [full_train.samples[i][1] for i in train_idx]\n",
    "\n",
    "class_counts = Counter(y_train)\n",
    "weights = torch.tensor([1.0 / class_counts[c] for c in range(num_classes)], dtype=torch.float)\n",
    "\n",
    "# Either use weighted loss...\n",
    "use_weighted_loss = True\n",
    "\n",
    "# ...or oversampling sampler (commented out by default)\n",
    "use_sampler = False\n",
    "if use_sampler:\n",
    "    sample_weights = [1.0 / class_counts[y] for y in y_train]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(y_train), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH, shuffle=(not use_sampler),\n",
    "    sampler=(sampler if use_sampler else None),\n",
    "    num_workers=NUMW, pin_memory=PIN\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False, num_workers=NUMW, pin_memory=PIN)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH, shuffle=False, num_workers=NUMW, pin_memory=PIN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce79994",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b264e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 1/40] train_loss=2.2873 acc=0.163 | val_loss=2.1936 acc=0.313\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 2/40] train_loss=2.1842 acc=0.234 | val_loss=2.1193 acc=0.340\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 3/40] train_loss=2.1117 acc=0.281 | val_loss=2.0623 acc=0.367\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 4/40] train_loss=2.0384 acc=0.363 | val_loss=2.0156 acc=0.393\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 5/40] train_loss=1.9753 acc=0.386 | val_loss=1.9638 acc=0.387\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 6/40] train_loss=1.9315 acc=0.389 | val_loss=1.9306 acc=0.373\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 7/40] train_loss=1.8882 acc=0.391 | val_loss=1.8995 acc=0.420\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 8/40] train_loss=1.8470 acc=0.420 | val_loss=1.8683 acc=0.387\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 9/40] train_loss=1.8184 acc=0.430 | val_loss=1.8453 acc=0.420\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 10/40] train_loss=1.8116 acc=0.427 | val_loss=1.8256 acc=0.393\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 11/40] train_loss=1.7765 acc=0.444 | val_loss=1.8115 acc=0.413\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 12/40] train_loss=1.7511 acc=0.430 | val_loss=1.7959 acc=0.420\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 13/40] train_loss=1.7191 acc=0.444 | val_loss=1.7791 acc=0.433\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 14/40] train_loss=1.7048 acc=0.453 | val_loss=1.7643 acc=0.427\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 15/40] train_loss=1.6929 acc=0.456 | val_loss=1.7623 acc=0.453\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 16/40] train_loss=1.6700 acc=0.479 | val_loss=1.7387 acc=0.433\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 17/40] train_loss=1.6593 acc=0.473 | val_loss=1.7435 acc=0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 18/40] train_loss=1.6646 acc=0.466 | val_loss=1.7288 acc=0.427\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 19/40] train_loss=1.6248 acc=0.481 | val_loss=1.7210 acc=0.427\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 20/40] train_loss=1.6308 acc=0.471 | val_loss=1.7167 acc=0.433\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 21/40] train_loss=1.6168 acc=0.490 | val_loss=1.7097 acc=0.413\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 22/40] train_loss=1.6200 acc=0.493 | val_loss=1.7155 acc=0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 23/40] train_loss=1.6355 acc=0.473 | val_loss=1.7000 acc=0.447\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 24/40] train_loss=1.6072 acc=0.476 | val_loss=1.6969 acc=0.447\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 25/40] train_loss=1.5828 acc=0.501 | val_loss=1.6915 acc=0.433\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 26/40] train_loss=1.5797 acc=0.486 | val_loss=1.6945 acc=0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 27/40] train_loss=1.5722 acc=0.511 | val_loss=1.6853 acc=0.427\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 28/40] train_loss=1.5866 acc=0.514 | val_loss=1.6846 acc=0.427\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 29/40] train_loss=1.5701 acc=0.507 | val_loss=1.6766 acc=0.427\n",
      "  ↳ saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 30/40] train_loss=1.5718 acc=0.491 | val_loss=1.6887 acc=0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 31/40] train_loss=1.5660 acc=0.493 | val_loss=1.6807 acc=0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 32/40] train_loss=1.5567 acc=0.500 | val_loss=1.6832 acc=0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 33/40] train_loss=1.5839 acc=0.501 | val_loss=1.6877 acc=0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HEAD 34/40] train_loss=1.5521 acc=0.533 | val_loss=1.6848 acc=0.427\n",
      "Early stopping (head).\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "head = model.get_classifier()          # timm helper\n",
    "if isinstance(head, nn.Module):\n",
    "    for p in head.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device) if use_weighted_loss else None)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_HEAD)\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_path = OUT_DIR / f\"{MODEL_NAME.replace('/','_')}_best.pt\"\n",
    "bad = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS_HEAD+1):\n",
    "    model.train()\n",
    "    tr_loss, tr_correct, n = 0.0, 0, 0\n",
    "    for x, y in tqdm(train_loader, leave=False):\n",
    "        x, y = x.to(device), torch.as_tensor(y, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        # Mixed precision only on CUDA; on MPS it’s still quirky → skip by default\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item() * y.size(0)\n",
    "        tr_correct += (logits.argmax(1) == y).sum().item()\n",
    "        n += y.size(0)\n",
    "    tr_acc = tr_correct / n\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct, m = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), torch.as_tensor(y, device=device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            val_loss += loss.item() * y.size(0)\n",
    "            val_correct += (logits.argmax(1) == y).sum().item()\n",
    "            m += y.size(0)\n",
    "    val_acc = val_correct / m\n",
    "    val_loss /= m\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"[HEAD {epoch}/{EPOCHS_HEAD}] train_loss={tr_loss/n:.4f} acc={tr_acc:.3f} | val_loss={val_loss:.4f} acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val, bad = val_loss, 0\n",
    "        torch.save({\"state_dict\": model.state_dict(), \"classes\": classes}, best_path)\n",
    "        print(\"  ↳ saved:\", best_path)\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= PATIENCE:\n",
    "            print(\"Early stopping (head).\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8e506",
   "metadata": {},
   "source": [
    "# Fine-tune deeper layers (low LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92235004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 1/6] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 2/6] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 3/6] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 4/6] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 5/6] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT 6/6] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# (Optional) open last blocks for FT; for VGG16 you can open more layers:\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "head = model.get_classifier()          # timm helper\n",
    "if isinstance(head, nn.Module):\n",
    "    for p in head.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5, weight_decay=1e-4)\n",
    "FT_EPOCHS = EPOCHS_FT\n",
    "\n",
    "for e in range(1, FT_EPOCHS+1):\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader, leave=False):\n",
    "        x, y = x.to(device), torch.as_tensor(y, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"[FT {e}/{FT_EPOCHS}] done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be50354",
   "metadata": {},
   "source": [
    "# Save & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d2d4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/fabianschwientek/code/gwen-m97/inspiart/inspiart/models/resnet18.a1_in1k_final.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (test):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Abstract_Expressionism      0.421     0.533     0.471        15\n",
      "                Cubism      0.533     0.533     0.533        15\n",
      "         Expressionism      0.286     0.133     0.182        15\n",
      "         Impressionism      0.450     0.600     0.514        15\n",
      "         Neoclassicism      0.417     0.667     0.513        15\n",
      "    Post-Impressionism      0.421     0.533     0.471        15\n",
      "               Realism      0.077     0.067     0.071        15\n",
      "           Romanticism      0.250     0.200     0.222        15\n",
      "            Surrealism      0.462     0.400     0.429        15\n",
      "             Symbolism      0.500     0.267     0.348        15\n",
      "\n",
      "              accuracy                          0.393       150\n",
      "             macro avg      0.382     0.393     0.375       150\n",
      "          weighted avg      0.382     0.393     0.375       150\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[ 8  0  2  1  0  2  0  0  0  2]\n",
      " [ 2  8  0  0  0  2  1  0  2  0]\n",
      " [ 2  4  2  0  3  2  1  0  0  1]\n",
      " [ 1  0  0  9  0  2  1  2  0  0]\n",
      " [ 0  0  0  0 10  0  0  3  2  0]\n",
      " [ 2  0  0  3  1  8  1  0  0  0]\n",
      " [ 0  0  1  5  4  2  1  2  0  0]\n",
      " [ 0  0  0  1  3  1  6  3  1  0]\n",
      " [ 3  2  2  0  1  0  0  0  6  1]\n",
      " [ 1  1  0  1  2  0  2  2  2  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "final_path = OUT_DIR / f\"{MODEL_NAME.replace('/','_')}_final.pt\"\n",
    "torch.save({\"state_dict\": model.state_dict(), \"classes\": classes}, final_path)\n",
    "print(\"Saved:\", final_path)\n",
    "\n",
    "# Test\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader, leave=False):\n",
    "        x = x.to(device)\n",
    "        logits = model(x).cpu()\n",
    "        y_true += list(y.numpy())\n",
    "        y_pred += list(logits.argmax(1).numpy())\n",
    "\n",
    "print(\"\\nClassification report (test):\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes, digits=3))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3246e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inspiart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
